{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42414602-35a7-4c6c-8f23-5b6b1f2e97eb",
   "metadata": {},
   "source": [
    "# Desinformaci√≥n y Deepfakes en la Era Digital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65f3ee-e088-4b2e-8ef7-325f1ed0d991",
   "metadata": {},
   "source": [
    "```{admonition} Pregunta inicial: \n",
    "¬øC√≥mo sabes si lo que ves en internet es real? ¬øPuedes confiar en todo lo que parece una foto o video aut√©ntico?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bb46d-590e-48cc-a6c4-52f86f607ddf",
   "metadata": {},
   "source": [
    "## Introducci√≥n\n",
    "\n",
    "<div align=\"justify\">\n",
    "Vivimos en una √©poca donde la tecnolog√≠a permite crear contenido falso tan convincente que es casi imposible distinguirlo de la realidad. Los deepfakes y la desinformaci√≥n representan uno de los desaf√≠os m√°s grandes de nuestro tiempo. <strong>Desinformaci√≥n</strong> es informaci√≥n falsa o enga√±osa creada y compartida deliberadamente con la intenci√≥n de enga√±ar o manipular</div>\n",
    "\n",
    "### Tipos de informaci√≥n falsa:\n",
    "\n",
    "1. **Desinformaci√≥n (Disinformation)**\n",
    "   - Informaci√≥n falsa creada **intencionalmente** para enga√±ar.\n",
    "   - Ejemplo: Noticias falsas sobre resultados electorales.\n",
    "   \n",
    "2. **Informaci√≥n err√≥nea (Misinformation)**\n",
    "   - Informaci√≥n falsa compartida **sin intenci√≥n** de enga√±ar.\n",
    "   - Ejemplo: Compartir un rumor que cre√≠ste verdadero. \n",
    "   \n",
    "3. **Malinformaci√≥n (Malinformation)**\n",
    "   - Informaci√≥n **verdadera** pero compartida para causar da√±o.\n",
    "   - Ejemplo: Filtraci√≥n de datos personales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d41cf-cce3-48a5-a36e-f69273884393",
   "metadata": {},
   "source": [
    "## DeepFakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf87de9-3487-4b27-b65c-0b999f91143e",
   "metadata": {},
   "source": [
    "```{admonition} ¬øQu√© es una <strong>Deepfake</strong>?\n",
    "<div align=\"justify\">Es una palabra que es el resultados de: <strong>Deep Learning + Fake</strong>. Son Videos, audios o im√°genes creados o alterados usando Inteligencia Artificial para hacer que una persona parezca decir o hacer algo que nunca hizo.</div><br>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16437035-2c0c-451c-8076-85edfbc478c4",
   "metadata": {},
   "source": [
    "### Tecnolog√≠a detr√°s de los Deepfakes:\n",
    "\n",
    "**Redes Neuronales Generativas Adversariales (GANs)**:\n",
    "- Una IA crea contenido falso\n",
    "- Otra IA intenta detectar si es falso\n",
    "- Compiten hasta que el falso es indistinguible del real\n",
    "\n",
    "### Ejemplo visual del proceso:\n",
    "\n",
    "**Pseudoc√≥digo** simplificado de c√≥mo funciona un deepfake\n",
    "\n",
    "def crear_deepfake(video_original, rostro_objetivo):\n",
    "   \n",
    "     1. Extraer rostro del video original\n",
    "    \n",
    "    rostros = extraer_rostros(video_original)\n",
    "    \n",
    "    2. Mapear rostro objetivo sobre cada frame\n",
    "    \n",
    "    for frame in rostros:\n",
    "        frame_falso = reemplazar_rostro(frame, rostro_objetivo)\n",
    "        ajustar_iluminacion(frame_falso)\n",
    "        ajustar_expresiones(frame_falso)\n",
    "    \n",
    "    3. Sincronizar audio con movimientos labiales\n",
    "    \n",
    "    sincronizar_labios(frames_falsos, audio_original)\n",
    "    \n",
    "    return video_deepfake\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4159bf5-5821-4248-a929-aff924aafcf1",
   "metadata": {},
   "source": [
    "## Casos Hist√≥ricos Famosos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e699986-963b-4a12-91c7-72d5a260fd93",
   "metadata": {},
   "source": [
    "### 1. Deepfake de Obama (2018)\n",
    "\n",
    "<div align=\"justify\">El director Jordan Peele cre√≥ un deepfake del expresidente Barack Obama para demostrar los peligros de esta tecnolog√≠a. En el video, \"Obama\" dice cosas que nunca dijo realmente.</div>\n",
    "\n",
    "**Objetivo**: Educar al p√∫blico sobre deepfakes\n",
    "**Resultado**: Millones de visualizaciones y conciencia sobre el problema\n",
    "\n",
    "### 2. Deepfake de Mark Zuckerberg (2019)\n",
    "\n",
    "Un video viral mostraba al CEO de Facebook diciendo:\n",
    "> \"Quien controla los datos, controla el futuro\"\n",
    "\n",
    "**Era falso**, pero sirvi√≥ para iniciar conversaciones sobre:\n",
    "- Privacidad de datos\n",
    "- Responsabilidad de las plataformas\n",
    "- Regulaci√≥n de deepfakes\n",
    "\n",
    "### 3. Caso Chileno: Desinformaci√≥n en el Plebiscito 2020\n",
    "\n",
    "Durante el plebiscito constitucional en Chile, \n",
    "\n",
    "**Ejemplos de desinformaci√≥n detectada**:\n",
    "\n",
    "- Capturas de pantalla falsas de medios\n",
    "- Videos editados de declaraciones pol√≠ticas\n",
    "- Noticias fabricadas sobre violencia\n",
    "- Manipulaci√≥n de encuestas\n",
    "\n",
    "**Impacto**: \n",
    "- Confusi√≥n en votantes\n",
    "- Polarizaci√≥n aumentada\n",
    "- Desconfianza en medios tradicionales\n",
    "\n",
    "### 4. Guerra en Ucrania (2022)\n",
    "\n",
    "Uno de los primeros conflictos con **abundante desinformaci√≥n por IA**:\n",
    "\n",
    "- Deepfake de Zelensky \"rindi√©ndose\" (falso)\n",
    "- Videos viejos presentados como actuales\n",
    "- Im√°genes generadas por IA de supuestas atrocidades\n",
    "\n",
    "## Tipos de Deepfakes\n",
    "\n",
    "### 1. **de Video**\n",
    "- Reemplazo de rostro completo\n",
    "- Manipulaci√≥n de expresiones\n",
    "- Ejemplo: Poner tu cara en una pel√≠cula\n",
    "\n",
    "### 2. **de Audio (Voice Cloning)**\n",
    "- Clonar voz de cualquier persona\n",
    "- Solo necesitan ~3-10 segundos de audio original\n",
    "- Aplicaciones: estafas telef√≥nicas, suplantaci√≥n\n",
    "\n",
    "### 3. **de Texto**\n",
    "- ChatGPT puede imitar estilos de escritura\n",
    "- Generar art√≠culos \"de peri√≥dicos\" falsos\n",
    "- Crear perfiles falsos en redes sociales\n",
    "\n",
    "### 4. **Cheapfakes** (manipulaci√≥n simple)\n",
    "- No usan IA avanzada\n",
    "- Edici√≥n b√°sica pero efectiva\n",
    "- Ejemplo: Videos en c√°mara lenta para hacer que alguien parezca ebrio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125eb4a-c5c1-42db-8090-c9ca0224fb21",
   "metadata": {},
   "source": [
    "><div align=\"justify\"> El impacto m√°s negativo que pueden causar los Deepfakes es generar en la sociedad una ausencia absoluta de confianza, lo que termine ocasionando un gran desinter√©s a la hora de diferenciar entre los archivos verdaderos y los Deepfakes. Cuando esta confianza es erosionada, se facilita mucho el hecho de generar dudas e inculcar ideas err√≥neas, dificultando el pensamiento cr√≠tico.</div>\n",
    "\n",
    "> Lisa Institute : \"Deepfakes: Qu√© es, tipos, riesgos y amenazas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f45e2-806b-4d34-abf1-ab9051d73ffe",
   "metadata": {},
   "source": [
    "## C√≥mo Detectar Deepfakes\n",
    "\n",
    "### Se√±ales visuales en videos: Checklist de detecci√≥n\n",
    "\n",
    "‚úì Parpadeo extra√±o o inexistente.\n",
    "\n",
    "‚úì Bordes del rostro borrosos.\n",
    "\n",
    "‚úì Iluminaci√≥n inconsistente.\n",
    "\n",
    "‚úì Movimientos labiales no sincronizados.\n",
    "\n",
    "‚úì Piel demasiado suave o artificial.\n",
    "\n",
    "‚úì Fondo pixelado o distorsionado.\n",
    "\n",
    "‚úì Joyas o accesorios que cambian.\n",
    "\n",
    "‚úì Sombras inconsistentes.\n",
    "\n",
    "### Herramientas de detecci√≥n:\n",
    "\n",
    "| Herramienta | Funci√≥n | Disponibilidad |\n",
    "|:-------------:|:---------|:----------------:|\n",
    "| **InVID** | Verificaci√≥n de videos | Gratis (extensi√≥n Chrome) |\n",
    "| **FotoForensics** | An√°lisis de manipulaci√≥n de im√°genes | Gratis (web) |\n",
    "| **TinEye** | B√∫squeda inversa de im√°genes | Gratis |\n",
    "| **Google Reverse Image** | Encontrar origen de im√°genes | Gratis |\n",
    "\n",
    "### Preguntas cr√≠ticas para verificar informaci√≥n:\n",
    "\n",
    "#### Checklist mental antes de compartir algo\n",
    "\n",
    "# def verificar_antes_compartir(contenido):\n",
    "    preguntas = [\n",
    "        \"¬øQui√©n cre√≥ este contenido?\",\n",
    "        \"¬øCu√°l es la fuente original?\",\n",
    "        \"¬øCu√°ndo fue publicado?\",\n",
    "        \"¬øPor qu√© fue creado? ¬øQu√© agenda tiene?\",\n",
    "        \"¬øD√≥nde m√°s ha sido reportado?\",\n",
    "        \"¬øMedios confiables lo confirman?\"\n",
    "    ]\n",
    "    \n",
    "    for pregunta in preguntas:\n",
    "        if not puedes_responder(pregunta):\n",
    "            return \"NO COMPARTAS - Verifica primero\"\n",
    "    \n",
    "    return \"Probablemente seguro compartir\"\n",
    "\n",
    "[Fuente](https://www.lisainstitute.com/blogs/blog/deepfakes-tipos-consejos-riesgos-amenazas?srsltid=AfmBOopzHMi1XzJawzoEUtdq35tfkFIsdDIwqX0CQXZr_D7QwiE6Ryvb) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da3a3a-efc2-47b9-b089-ceefb3d59d51",
   "metadata": {},
   "source": [
    "><div align=\"justify\">Los contenidos lascivos y ficticios creados con esta tecnolog√≠a (IA) representan el 98% de todos los videos deepfake en l√≠nea. Durante el √∫ltimo a√±o, el contenido sexual ultrafalso registr√≥ un aumento del 400%. Alcanz√≥ un tr√°fico mensual superior a 34  millones de usuarios en 2023. El 99% de los destinatarios fueron mujeres. ‚ÄúEsto sigue una tendencia preexistente en la violencia de g√©nero facilitada por la tecnolog√≠a, donde el 58% de las mujeres j√≥venes y ni√±as en todo el mundo han experimentado acoso en l√≠nea en plataformas de redes sociales, con un impacto desproporcionado experimentado seg√∫n el g√©nero, la raza y el origen √©tnico, orientaci√≥n sexual, religi√≥n y otros factores.</div>\n",
    "\n",
    ">Disrupting the Deepfake Supply Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa33e723-fc38-400d-b1b2-69f1626ecd2d",
   "metadata": {},
   "source": [
    "## Impacto de la Desinformaci√≥n\n",
    "\n",
    "### En la Democracia:\n",
    "- ‚ùå Interferencia en elecciones\n",
    "- ‚ùå Desconfianza en instituciones\n",
    "- ‚ùå Polarizaci√≥n extrema\n",
    "- ‚ùå Manipulaci√≥n de opini√≥n p√∫blica\n",
    "\n",
    "### En la Sociedad:\n",
    "- ‚ùå Teor√≠as conspirativas\n",
    "- ‚ùå Rechazo a vacunas (ej: COVID-19)\n",
    "- ‚ùå Violencia basada en rumores\n",
    "- ‚ùå Da√±o a reputaciones\n",
    "\n",
    "### En Individuos:\n",
    "- ‚ùå Chantaje con deepfakes sexuales\n",
    "- ‚ùå Estafas de suplantaci√≥n de voz\n",
    "- ‚ùå Bullying con contenido falso\n",
    "- ‚ùå P√©rdida de confianza en medios\n",
    "\n",
    "## Casos de Uso Leg√≠timos de esta Tecnolog√≠a\n",
    "\n",
    "No todo es negativo. La misma tecnolog√≠a tiene usos positivos:\n",
    "\n",
    "### 1. **Entretenimiento**\n",
    "- Efectos especiales en pel√≠culas\n",
    "- Rejuvenecimiento de actores (ej: \"The Irishman\")\n",
    "- Resurrecci√≥n digital de actores fallecidos\n",
    "\n",
    "### 2. **Educaci√≥n**\n",
    "- Traducci√≥n de videos a otros idiomas con labios sincronizados\n",
    "- Recreaci√≥n de figuras hist√≥ricas\n",
    "- Simulaciones interactivas\n",
    "\n",
    "### 3. **Accesibilidad**\n",
    "- Voces sint√©ticas para personas con problemas de habla\n",
    "- Avatares para personas con discapacidades\n",
    "- Asistentes virtuales personalizados\n",
    "\n",
    "### 4. **Medicina**\n",
    "- Simulaciones de procedimientos\n",
    "- Entrenamiento m√©dico\n",
    "- Terapia psicol√≥gica (avatares de terapeutas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c0c56-904c-4706-acc2-b6a956459be8",
   "metadata": {},
   "source": [
    "## Ejemplo Hist√≥rico: Propaganda en la Historia\n",
    "\n",
    "La desinformaci√≥n no es nueva, solo las herramientas han cambiado:\n",
    "\n",
    "### Propaganda Nazi (1933-1945)\n",
    "- **T√©cnica**: Fotograf√≠as retocadas manualmente\n",
    "- **Objetivo**: Eliminar enemigos de Stalin de fotos hist√≥ricas\n",
    "- **Tecnolog√≠a**: Edici√≥n manual y reimpresi√≥n\n",
    "\n",
    "### Propaganda Sovi√©tica\n",
    "- **Ejemplo famoso**: Eliminaci√≥n de Trotsky de fotograf√≠as\n",
    "- **M√©todo**: Retoque f√≠sico de negativos\n",
    "\n",
    "### Chile: Propaganda durante la Dictadura\n",
    "- **Medios controlados** presentaban versi√≥n oficial\n",
    "- **Censura** de informaci√≥n contraria\n",
    "- **Desaparici√≥n** de registros hist√≥ricos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd228b6c-6d28-4dd5-9b37-fa6b75e78d3b",
   "metadata": {},
   "source": [
    "><div align=\"justify\">‚ÄúPara que una sociedad moderna funcione, las personas necesitan tener acceso a informaci√≥n cre√≠ble y aut√©ntica. Enga√±ar al p√∫blico mediante el uso de la IA deber√≠a regularse y aplicarse mediante leyes espec√≠ficas y formalizadas. Cada vez es m√°s dif√≠cil identificar qu√© es real en internet. Es necesario trazar l√≠neas para proteger nuestra capacidad de reconocer a seres humanos reales‚Äù</div>\n",
    "\n",
    ">Disrupting the Deepfake Supply Chain (2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c432b81-8be7-4190-b143-602f647379cf",
   "metadata": {},
   "source": [
    "## C√≥mo Protegerte de la Desinformaci√≥n\n",
    "\n",
    "### 1. **Desarrolla Alfabetizaci√≥n Medi√°tica**\n",
    "\n",
    "- Identificar fuentes confiables\n",
    "- Verificar informaci√≥n antes de compartir\n",
    "- Entender sesgos en medios\n",
    "- Reconocer t√©cnicas de manipulaci√≥n\n",
    "- Buscar m√∫ltiples perspectivas\n",
    "\n",
    "### 2. **Usa el M√©todo SIFT**\n",
    "\n",
    "**S**top - Detente antes de compartir\n",
    "**I**nvestigate the source - Investiga la fuente\n",
    "**F**ind better coverage - Busca mejor cobertura\n",
    "**T**race to original - Rastrea hasta el original\n",
    "\n",
    "### 3. **Verifica con Fact-Checkers**\n",
    "\n",
    "Sitios de verificaci√≥n en espa√±ol:\n",
    "- **Maldita.es** (Espa√±a)\n",
    "- **Newtral** (Espa√±a)\n",
    "- **Fast Check CL** (Chile)\n",
    "- **AFP Factual** (Global)\n",
    "- **Chequeado** (Argentina)\n",
    "\n",
    "### 4. **Configura tu Privacidad**\n",
    "\n",
    "**Protege tu imagen y voz**:\n",
    "- Configura privacidad en redes sociales\n",
    "- Limita qui√©n puede ver tus fotos/videos\n",
    "- No compartas material sensible p√∫blicamente\n",
    "- Usa autenticaci√≥n de dos factores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e7deb-749b-4bed-babc-087b471056b0",
   "metadata": {},
   "source": [
    "## Marco Legal Actual\n",
    "\n",
    "### Internacional:\n",
    "- **UE**: AI Act incluye regulaci√≥n de deepfakes\n",
    "- **EE.UU.**: Algunas leyes estatales (California, Texas)\n",
    "- **China**: Requiere marca de agua en contenido sint√©tico\n",
    "\n",
    "### Chile:\n",
    "- ‚ùå **No existe legislaci√≥n espec√≠fica** sobre deepfakes\n",
    "- ‚ö†Ô∏è **Vac√≠o legal** preocupante\n",
    "- üìù **Necesidad urgente** de regulaci√≥n\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af79e660-f6a3-45df-ac6f-f049675968f5",
   "metadata": {},
   "source": [
    "## El Futuro de los Deepfakes\n",
    "\n",
    "### Tendencias preocupantes:\n",
    "- üìà **M√°s accesibles**: Apps m√≥viles que cualquiera puede usar\n",
    "- üìà **M√°s realistas**: Dif√≠cil distinguir de videos reales\n",
    "- üìà **M√°s r√°pidos**: Crear deepfakes en minutos, no horas\n",
    "- üìà **Audio perfecto**: Clonaci√≥n de voz casi perfecta\n",
    "\n",
    "### Posibles soluciones:\n",
    "\n",
    "#### Tecnol√≥gicas:\n",
    "- **Marcas de agua digitales** en contenido aut√©ntico\n",
    "- **Blockchain** para verificar origen de medios\n",
    "- **IA detectora** que evoluciona junto a deepfakes\n",
    "- **Autenticaci√≥n biom√©trica** en c√°maras\n",
    "\n",
    "#### Legales:\n",
    "- **Leyes contra deepfakes maliciosos**\n",
    "- **Responsabilidad de plataformas**\n",
    "- **Derecho al olvido** de contenido falso\n",
    "- **Sanciones por desinformaci√≥n intencional**\n",
    "\n",
    "#### Educativas:\n",
    "- **Alfabetizaci√≥n medi√°tica** en escuelas\n",
    "- **Pensamiento cr√≠tico** como habilidad central\n",
    "- **Verificaci√≥n** como h√°bito digital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c290ca-4079-4a89-b23b-5ce1460c1bf6",
   "metadata": {},
   "source": [
    "><div align=\"justify\">\"La mejor forma de combatir la difusi√≥n de noticias falsas podr√≠a ser acudir a las personas. Las consecuencias sociales de las noticias falsas ‚Äìmayor polarizaci√≥n pol√≠tica, aumento del partidismo, erosi√≥n de la confianza en los medios de comunicaci√≥n convencionales y en el Gobierno‚Äì son significativas. Si m√°s personas supieran lo que est√° en juego, quiz√° ser√≠an m√°s precavidas con la informaci√≥n, en especial si tiene una base emocional, porque ese es un modo eficaz de llamar la atenci√≥n de la ciudadan√≠a\".</div>\n",
    "\n",
    ">Anjana Susarla (2018): Como puede la inteligencia artificial detectar y crear noticias falsas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae15a96-e47f-40d9-b3fc-393ca6b0ace2",
   "metadata": {},
   "source": [
    "## Recursos para Profundizar\n",
    "\n",
    "- **Documental**: \"The Social Dilemma\" - Netflix\n",
    "- **Video**: \"You Won't Believe What Obama Says In This Video!\" - BuzzFeed\n",
    "- **Sitio**: ThisPersonDoesNotExist.com (rostros generados por IA)\n",
    "- **Organizaci√≥n**: First Draft News (verificaci√≥n de hechos)\n",
    "- **Manifiesto**: Disrupting the Deepfake Supply Chain.\n",
    "\n",
    "## Conclusi√≥n\n",
    "**Tres reglas de oro**:\n",
    "1. **Duda**: No todo lo que ves es real\n",
    "2. **Verifica**: Usa herramientas de fact-checking\n",
    "3. **Educa**: Comparte tu conocimiento con otros\n",
    "\n",
    "La mejor defensa contra la desinformaci√≥n es una ciudadan√≠a educada y cr√≠tica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea5607-a9c5-47a0-96b1-9ce4c4e045ed",
   "metadata": {},
   "source": [
    "## Actividad Pr√°ctica: Detective de Deepfakes\n",
    "\n",
    "**Instrucciones**:\n",
    "1. Busca en YouTube: \"deepfake examples\"\n",
    "2. Elige 3 videos diferentes\n",
    "3. Para cada uno, identifica:\n",
    "   - ¬øQu√© se√±ales visuales de manipulaci√≥n ves?\n",
    "   - ¬øC√≥mo podr√≠as verificar si es real?\n",
    "   - ¬øQu√© da√±o podr√≠a causar si fuera compartido como real?\n",
    "   \n",
    "**Informe**: Documento con tus hallazgos y capturas de pantalla\n",
    "\n",
    "---\n",
    "\n",
    "**Pr√≥xima clase**: Exploraremos la privacidad y protecci√≥n de datos personales en la era digital.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
